
[synchronized]

可以保证方法或者代码块在运行时，同一时刻只有一个方法可以进入到临界区，
同时它还可以保证共享变量的内存可见性

Java中每一个对象都可以作为锁，这是synchronized实现同步的基础：

1.普通同步方法，锁是当前实例对象

2.静态同步方法，锁是当前类的class对象

3.同步方法块，锁是括号里面的对象







/-----------------------------------------------------------------------------------/
同步代码块：线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor所有权，即尝试获取对象的锁；

同步方法：在Class字节码文件的方法表中将该方法的access_flags字段中的synchronized标志位置1，
表示该方法是同步方法并使用调用该方法的对象或该方法所属的Class在JVM的内部对象表示Klass做为锁对象。








/-----------------------------------------------------------------------------------/
Java对象头和monitor是实现synchronized的基础

[Java对象头]

1.synchronized用的锁是存在Java对象头里

2.对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针)

3.Klass Point是是对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例

4.Mark Word用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等等。它是实现轻量级锁和偏向锁的关键

Java对象头一般占有两个机器码（在32位虚拟机中，1个机器码等于4字节，也就是32bit）
下图是Java对象头的存储结构（32位虚拟机）：

----------------------------------------------------------------------------------------------------
            25bit       |            4bit       |          1bit         |            2bit       |
----------------------------------------------------------------------------------------------------
       对象的hashCode   |       对象的分代年龄  |       是否是偏向锁    |           锁标志位    |
----------------------------------------------------------------------------------------------------



----------------------------------------------------------------------------
            锁状态       |     是否是偏向锁（1bit）    |  锁标志位（2bit）       
----------------------------------------------------------------------------
           无锁状态      |             0                |          01  
           轻量级锁      |             0                |          00  
           重量级锁      |             0                |          10  
           GC标志        |             0                |          11  
           偏向锁        |             1                |          01  
----------------------------------------------------------------------------
（http://cmsblogs.com/?p=2071）
 

对象头信息是与对象自身定义的数据无关的额外存储成本，但是考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据，它会根据对象的状态复用自己的存储空间，也就是说，Mark Word会随着程序的运行发生变化


[Monitor]

Monitor可以把它理解为一个同步工具，也可以描述为一种同步机制，它通常被描述为一个对象。
每一个被锁住的对象都会和一个monitor关联（对象头的MarkWord中的LockWord指向monitor的起始地址）
同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用










/-----------------------------------------------------------------------------------/
[锁优化]

1.自旋锁
让该线程等待一段时间，不会被立即挂起，看持有锁的线程是否会很快释放锁，即执行一段无意义的循环，循环默认次数10（自旋）。

2.适应自旋锁
线程如果自旋成功了，那么下次自旋的次数会更加多，因为虚拟机认为既然上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多。反之，如果对于某个锁，很少有自旋能够成功的，那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源。

3.锁消除
如果不存在竞争，为什么还需要加锁呢？所以锁消除可以节省毫无意义的请求锁的时间。
如StringBuffer、Vector、HashTable等，这个时候会存在隐形的加锁操作
-----------------------------------------------------------------------------------

    public void vectorTest(){

        Vector<String> vector = new Vector<String>();

        for(int i = 0 ; i < 10 ; i++){
            vector.add(i + "");
        }

        System.out.println(vector);

    }

-----------------------------------------------------------------------------------
在运行这段代码时，JVM可以明显检测到变量vector没有逃逸出方法vectorTest()之外，所以JVM可以大胆地将vector内部的加锁操作消除。

4.锁粗化
将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁。
如上面实例：vector每次add的时候都需要加锁操作，JVM检测到对同一个对象（vector）连续加锁、解锁操作，会合并一个更大范围的加锁、解锁操作，即加锁解锁操作会移到for循环之外。

5.轻量级锁

1）获取锁

【1】.判断当前对象是否处于无锁状态（hashcode、0、01），若是，则JVM首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝（官方把这份拷贝加了一个Displaced前缀，即Displaced Mark Word）；否则执行步骤（3）；

【2】.JVM利用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指正，
如果成功表示竞争到锁，则将锁标志位变成00（表示此对象处于轻量级锁状态），执行同步操作；如果失败则执行步骤（3）；

【3】.判断当前对象的Mark Word是否指向当前线程的栈帧，如果是则表示当前线程已经持有当前对象的锁，则直接执行同步代码块；否则只能说明该锁对象已经被其他线程抢占了，这时轻量级锁需要膨胀为重量级锁，锁标志位变成10，后面等待的线程将会进入阻塞状态；


2）释放锁

轻量级锁的释放也是通过CAS操作来进行的，主要步骤如下：

【1】.取出在获取轻量级锁保存在Displaced Mark Word中的数据；

【2】.用CAS操作将取出的数据替换当前对象的Mark Word中，如果成功，则说明释放锁成功，否则执行（3）；

【3】.如果CAS操作替换失败，说明有其他线程尝试获取该锁，则需要在释放锁的同时需要唤醒被挂起的线程。

查看【（锁获取&释放）轻量级锁的获取和释放过程】图片


6.偏向锁

引入偏向锁主要目的是：为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径。上面提到了轻量级锁的加锁解锁操作是需要依赖多次CAS原子指令的。那么偏向锁是如何来减少不必要的CAS操作呢？我们可以查看Mark work的结构就明白了。只需要检查是否为偏向锁、锁标识为以及ThreadID即可

1）获取锁

【1】.检测Mark Word是否为可偏向状态，即是否为偏向锁1，锁标识位为01；

【2】.若为可偏向状态，则测试线程ID是否为当前线程ID，如果是，则执行步骤（5），否则执行步骤（3）；

【3】.如果线程ID不为当前线程ID，则通过CAS操作竞争锁，竞争成功，则将Mark Word的线程ID替换为当前线程ID，否则执行线程（4）；

【4】.通过CAS竞争锁失败，证明当前存在多线程竞争情况，当到达全局安全点，获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，
然后被阻塞在安全点的线程继续往下执行同步代码块；

【5】.执行同步代码块

2）释放锁

查看【（锁获取&释放）偏向锁的获取和释放流程】图片


7.重量级锁

重量级锁通过对象内部的监视器（monitor）实现，其中monitor的本质是依赖于底层操作系统的Mutex Lock实现，操作系统实现线程之间的切换需要从用户态到内核态的切换，切换成本非常高。














/-----------------------------------------------------------------------------------/
/-----------------------------------我是分割线--------------------------------------/
/-----------------------------------------------------------------------------------/

[volatile]

volatile是轻量级的synchronized

一个变量如果用volatile修饰了，则Java可以确保所有线程看到这个变量的值是一致的，如果某个线程对volatile修饰的共享变量进行更新，那么其他线程可以立马看到这个更新，这就是所谓的线程可见性。


/-----------------------------------------------------------------------------------/

[java内存模型相关概念]

计算机在运行程序时，每条指令都是在CPU中执行的，在执行过程中势必会涉及到数据的读写。我们知道程序运行的数据是存储在主存中，这时就会有一个问题，读写主存中的数据没有CPU中执行指令的速度快，如果任何的交互都需要与主存打交道则会大大影响效率，所以就有了CPU高速缓存。CPU高速缓存为某个CPU独有，只与在该CPU运行的线程有关。

有了CPU高速缓存虽然解决了效率问题，但是它会带来一个新的问题：数据一致性。在程序运行中，会将运行所需要的数据复制一份到CPU高速缓存中，在进行运算时CPU不再也主存打交道，而是直接从高速缓存中读写数据，只有当运行结束后才会将数据刷新到主存中。举一个简单的例子：

---------------------
 i++
---------------------

当线程运行这段代码时，首先会从主存中读取i( i = 1)，然后复制一份到CPU高速缓存中，然后CPU执行 + 1 （2）的操作，然后将数据（2）写入到告诉缓存中，最后刷新到主存中。其实这样做在单线程中是没有问题的，有问题的是在多线程中。如下：

假如有两个线程A、B都执行这个操作（i++），按照我们正常的逻辑思维主存中的i值应该=3，但事实是这样么？分析如下：

两个线程从主存中读取i的值（1）到各自的高速缓存中，然后线程A执行+1操作并将结果写入高速缓存中，最后写入主存中，此时主存i==2,线程B做同样的操作，主存中的i仍然=2。所以最终结果为2并不是3。这种现象就是缓存一致性问题。

解决缓存一致性方案有两种：

1).通过在总线加LOCK#锁的方式

2).通过缓存一致性协议

但是方案1存在一个问题，它是采用一种独占的方式来实现的，即总线加LOCK#锁的话，只能有一个CPU能够运行，其他CPU都得阻塞，效率较为低下。

第二种方案，缓存一致性协议（MESI协议）它确保每个缓存中使用的共享变量的副本是一致的。其核心思想如下：当某个CPU在写数据时，如果发现操作的变量是共享变量，则会通知其他CPU告知该变量的缓存行是无效的，因此其他CPU在读取该变量时，发现其无效会重新从主存中加载数据。




/-----------------------------------------------------------------------------------/

[java内存模型]

///////原子性///////：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。

-------------------------------------------------------------
  i = 0;             ------1

  j = i ;            ------2
  
  i++;               ------3
  
  i = j + 1;         ------4
-------------------------------------------------------------

1—在Java中，对基本数据类型的变量和赋值操作都是原子性操作；
2—包含了两个操作：读取i，将i值赋值给j
3—包含了三个操作：读取i值、i + 1 、将+1结果赋值给i；
4—同三一样

在单线程环境下我们可以认为整个步骤都是原子性操作，但是在多线程环境下则不同，Java只保证了基本数据类型的变量和赋值操作才是原子性的（注：在32位的JDK环境下，对64位数据的读取不是原子性操作*，如long、double）。要想在多线程环境下保证原子性，则可以通过锁、synchronized来确保。

[volatile是无法保证复合操作的原子性]



///////可见性///////：指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。
Java提供了volatile来保证可见性。
当一个变量被volatile修饰后，表示着线程本地内存无效，当一个线程修改共享变量后他会立即被更新到主内存中，当其他线程读取共享变量时，它会直接从主内存中读取。当然，synchronize和锁都可以保证可见性。


///////有序性///////：即程序执行的顺序按照代码的先后顺序执行。
在Java内存模型中，为了效率是允许编译器和处理器对指令进行重排序，当然重排序它不会影响单线程的运行结果，但是对多线程会有影响。
Java提供volatile来保证一定的有序性。





/-----------------------------------------------------------------------------------/

[剖析volatile原理]

1.保证可见性、不保证原子性

2.禁止指令重排序

在执行程序时为了提高性能，编译器和处理器通常会对指令做重排序：

1.编译器重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序；

2.处理器重排序。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序；



happen-before原则保证了程序的“有序性”

查看【（volatile）happen-before原则】图片

观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令。
lock前缀指令其实就相当于一个内存屏障。内存屏障是一组处理指令，用来实现对内存操作的顺序限制。
volatile的底层就是通过内存屏障来实现的。





/-----------------------------------------------------------------------------------/

[volatile总结]

volatile相对于synchronized稍微轻量些，在某些场合它可以替代synchronized，但是又不能完全取代synchronized，
只有在某些场合才能够使用volatile。使用它必须满足如下两个条件：

1.对变量的写操作不依赖当前值；

2.该变量没有包含在具有其他变量的不变式中。



















/-----------------------------------------------------------------------------------/
/-------------------------------------我是分割线------------------------------------/
/-----------------------------------------------------------------------------------/

[happens-before]

JMM就使用happens-before的概念来阐述多线程之间的内存可见性。

在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系。

happens-before原则非常重要，它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们解决在并发环境下两操作之间是否可能存在冲突的所有问题。

-------------------------------------------------------------

i = 1;       //线程A执行

j = i ;      //线程B执行

-------------------------------------------------------------
j 是否等于1呢？假定线程A的操作（i = 1）happens-before线程B的操作（j = i）,那么可以确定线程B执行后j = 1 一定成立，如果他们不存在happens-before原则，那么j = 1 不一定成立。这就是happens-before原则的威力。

happens-before原则定义如下：

1. 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。

2. 两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。


**************************************************重要**************************************************

下面是happens-before原则规则：

1.程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作；
2.锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作；
3.volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；
4.传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；
5.线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作；
6.线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；
7.线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；
8.对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始；

**************************************************重要**************************************************

8条规则总结于下：

1.程序次序规则：一段代码在单线程中执行的结果是有序的。注意是执行结果，因为虚拟机、处理器会对指令进行重排序（重排序后面会详细介绍）。虽然重排序了，但是并不会影响程序的执行结果，所以程序最终执行的结果与顺序执行的结果是一致的。故而这个规则只对单线程有效，在多线程环境下无法保证正确性。

2.volatile变量规则：这是一条比较重要的规则，它标志着volatile保证了线程可见性。通俗点讲就是如果一个线程先去写一个volatile变量，然后一个线程去读这个变量，那么这个写操作一定是happens-before读操作的。

3.传递规则：提现了happens-before原则具有传递性，即A happens-before B , B happens-before C，那么A happens-before C

4.线程启动规则：假定线程A在执行过程中，通过执行ThreadB.start()来启动线程B，那么线程A对共享变量的修改在接下来线程B开始执行后确保对线程B可见。

5.线程终结规则：假定线程A在执行的过程中，通过制定ThreadB.join()等待线程B终止，那么线程B在终止之前对共享变量的修改在线程A等待返回后可见。


上面八条是原生Java满足Happens-before关系的规则，但是我们可以对他们进行推导出其他满足happens-before的规则：

1.将一个元素放入一个线程安全的队列的操作Happens-Before从队列中取出这个元素的操作

2.将一个元素放入一个线程安全容器的操作Happens-Before从容器中取出这个元素的操作

3.在CountDownLatch上的倒数操作Happens-Before CountDownLatch#await()操作 ----------不了解  ???

4.释放Semaphore许可的操作Happens-Before获得许可操作 ----------不了解  ???

5.Future表示的任务的所有操作Happens-Before Future#get()操作 ----------不了解  ???

6.向Executor提交一个Runnable或Callable的操作Happens-Before任务开始执行操作


如果两个操作不存在上述（前面8条 + 后面6条）任一一个happens-before规则，那么这两个操作就没有顺序的保障，JVM可以对这两个操作进行重排序。如果操作A happens-before操作B，那么操作A在内存上所做的操作对操作B都是可见的。


/-----------------------------------------------------------------------------------/

下面就用一个简单的例子来描述下happens-before原则：

-------------------------------------------------------------

private int i = 0;

public void write(int j ){
    i = j;
}

public int read(){
    return i;
}

-------------------------------------------------------------

我们约定线程A执行write()，线程B执行read()，且线程A优先于线程B执行，那么线程B获得结果是什么？；

我们就这段简单的代码一次分析happens-before的规则（规则5、6、7、8 + 推导的6条可以忽略，因为他们和这段代码毫无关系）：

1.由于两个方法是由不同的线程调用，所以肯定不满足程序次序规则；
2.两个方法都没有使用锁，所以不满足锁定规则；
3.变量i不是用volatile修饰的，所以volatile变量规则不满足；
4.传递规则肯定不满足；

所以我们无法通过happens-before原则推导出线程A happens-before线程B，虽然可以确认在时间上线程A优先于线程B指定，
但是就是无法确认线程B获得的结果是什么，所以这段代码不是线程安全的。
那么怎么修复这段代码呢？满足规则2、3任一即可。




















/-----------------------------------------------------------------------------------/
/-----------------------------------我是分割线--------------------------------------/
/-----------------------------------------------------------------------------------/

[重排序]

在执行程序时，为了提供性能，处理器和编译器常常会对指令进行重排序，但是不能随意重排序，它需要满足以下两个条件：

1.在单线程环境下不能改变程序运行的结果；

2.存在数据依赖关系的不允许重排序

这两点可以归结于一点：无法通过happens-before原则推导出来的，JMM允许任意的排序。


/-----------------------------------------------------------------------------------/

[as-if-serial语义]

as-if-serial语义的意思是，所有的操作均可以为了优化而被重排序，但是你必须要保证重排序后执行的结果不能被改变，编译器、runtime、处理器都必须遵守as-if-serial语义。注意as-if-serial只保证单线程环境，多线程环境下无效。







下面我们用一个简单的示例来说明：


-------------------------------------------------------------
int a = 1 ;      //A
int b = 2 ;      //B
int c = a + b;   //C
-------------------------------------------------------------


A、B、C三个操作存在如下关系：A、B不存在数据依赖关系，A和C、B和C存在数据依赖关系，因此在进行重排序的时候，A、B可以随意排序，但是必须位于C的前面，执行顺序可以是A –> B –> C或者B –> A –> C。但是无论是何种执行顺序最终的结果C总是等于3。

as-if-serail语义把单线程程序保护起来了，它可以保证在重排序的前提下程序的最终结果始终都是一致的。

其实对于上段代码，他们存在这样的happen-before关系：

A happens-before B
B happens-before C
A happens-before C

1、2是程序顺序次序规则，3是传递性。但是，不是说通过重排序，B可能会排在A之前执行么，为何还会存在存在A happens-beforeB呢？这里再次申明A happens-before B不是A一定会在B之前执行，而是A的对B可见，但是相对于这个程序A的执行结果不需要对B可见，且他们重排序后不会影响结果，所以JMM不会认为这种重排序非法。

我们需要明白这点：在不改变程序执行结果的前提下，尽可能提高程序的运行效率。





下面我们在看一段有意思的代码：

-------------------------------------------------------------
public class RecordExample1 {
    public static void main(String[] args){
        int a = 1;
        int b = 2;

        try {
            a = 3;           //A
            b = 1 / 0;       //B
        } catch (Exception e) {

        } finally {
            System.out.println("a = " + a);
        }
    }
}
-------------------------------------------------------------

按照重排序的规则，操作A与操作B有可能会进行重排序，如果重排序了，B会抛出异常（ / by zero），此时A语句一定会执行不到，那么a还会等于3么？如果按照as-if-serial原则它就改变了程序的结果。其实JVM对异常做了一种特殊的处理，为了保证as-if-serial语义，Java异常处理机制对重排序做了一种特殊的处理：JIT在重排序时会在catch语句中插入错误代偿代码（a = 3）,这样做虽然会导致cathc里面的逻辑变得复杂，但是JIT优化原则是：尽可能地优化程序正常运行下的逻辑，哪怕以catch块逻辑变得复杂为代价







/-----------------------------------------------------------------------------------/

[重排序对多线程的影响]


-------------------------------------------------------------
public class RecordExample2 {
    int a = 0;
    boolean flag = false;

    /**
     * A线程执行
     */
    public void writer(){
        a = 1;                  // 1
        flag = true;            // 2
    }

    /**
     * B线程执行
     */
    public void read(){
        if(flag){                  // 3
           int i = a + a;          // 4
        }
    }

}
-------------------------------------------------------------
      线程A       |        线程B
                  |
  flag = true     |
                  |
                  |
                  |
  				  |		if(flag)
                  |
                  |
                  |
  				  |		int i = a + a
                  |
	              |
  a = 1           |
                  |  90
                  |
-------------------------------------------------------------

按照这种执行顺序线程B肯定读不到线程A设置的a值，在这里多线程的语义就已经被重排序破坏了。

操作3 和操作4 之间也可以重排序
假如操作3 和操作4重排序了，操作4 先执行，则先会把计算结果临时保存到重排序缓冲中，当操作3 为真时才会将计算结果写入变量i中


[总结]

通过上面的分析，重排序不会影响单线程环境的执行结果，但是会破坏多线程的执行语义。




















/-----------------------------------------------------------------------------------/
/-----------------------------------我是分割线--------------------------------------/
/-----------------------------------------------------------------------------------/

[Java内存模型之分析volatile（详解）]


前篇博客[深入分析volatile的实现原理]中已经阐述了volatile的特性：


1.volatile可见性；对一个volatile的读，总可以看到对这个变量最终的写；

2.volatile原子性；volatile对单个读/写具有原子性（32位Long、Double），但是复合操作除外，例如i++;

3.JVM底层采用“内存屏障”来实现volatile语义



/-----------------------------------------------------------------------------------/

[volatile与happens-before]

下面用例子来分析volatile变量的读写建立的happens-before关系。

-------------------------------------------------------------
public class VolatileTest {

    int i = 0;
    volatile boolean flag = false;

    //Thread A
    public void write(){
        i = 2;              //1
        flag = true;        //2
    }

    //Thread B
    public void read(){
        if(flag){                                   //3
            System.out.println("---i = " + i);      //4
        }
    }
}
-------------------------------------------------------------
依据happens-before原则，就上面程序得到如下关系：

依据happens-before程序顺序原则：1 happens-before 2、3 happens-before 4；
根据happens-before的volatile原则：2 happens-before 3；
根据happens-before的传递性：1 happens-before 4  (1对于4 可见)

volatile除了保证可见性外，还有就是禁止重排序。
所以A线程在写volatile变量之前所有可见的共享变量，在线程B读同一个volatile变量后，将立即变得对线程B可见。







/-----------------------------------------------------------------------------------/

[volataile的内存语义及其实现]

在JMM中，线程之间的通信采用共享内存来实现的。volatile的内存语义是：

当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值立即刷新到主内存中。

当读一个volatile变量时，JMM会把该线程对应的本地内存设置为无效，直接从主内存中读取共享变量。

所以volatile的写内存语义是直接刷新到主内存中，读的内存语义是直接从主内存中读取。
那么volatile的内存语义是如何实现的呢？
对于一般的变量则会被重排序，而对于volatile则不能，这样会影响其内存语义，所以为了实现volatile的内存语义JMM会限制重排序。
其重排序规则如下：

1.当第一个操作为volatile读，则不管第二个操作是啥，都不能重排序。这个操作确保volatile读之后的操作不会被编译器重排序到volatile读之前；

2.当第二个操作为volatile写，则不管第一个操作是啥，都不能重排序。这个操作确保volatile写之前的操作不会被编译器重排序到volatile写之后；

3.当第一个操作volatile写，第二操作为volatile读时，不能重排序。




volatile的底层实现是通过插入内存屏障，但是对于编译器来说，发现一个最优布置来最小化插入内存屏障的总数几乎是不可能的，所以，JMM采用了保守策略。如下：

1.在每一个volatile写操作前面插入一个StoreStore屏障
2.在每一个volatile写操作后面插入一个StoreLoad屏障
3.在每一个volatile读操作后面插入一个LoadLoad屏障
4.在每一个volatile读操作后面插入一个LoadStore屏障

StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作都已经刷新到主内存中。

StoreLoad屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序。

LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序。

LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序。


还是用VolatileTest来分析：
-------------------------------------------------------------
public class VolatileTest {

    int i = 0;
    volatile boolean flag = false;

    //Thread A
    public void write(){
        i = 2;              //1
        flag = true;        //2
    }

    //Thread B
    public void read(){
        if(flag){                                   //3
            System.out.println("---i = " + i);      //4
        }
    }
}
-------------------------------------------------------------

i = 2;                  //普通写

插入StoreStore屏障      //禁止上面的普通写与下面的volatile写重排序

flag = true             //Volatile写

插入StoreLoad屏障       //禁止上面的volatile写下面可能有的volatile读/写重排序




if(flag)                //Volatile读

插入LoadLoad屏障        //禁止处理器把上面的volatile读与下面的普通读重排序

LoadStore屏障           //禁止处理器把上面的volatile读与下面的普通写重排序

System.out.println("---i = " + i);              //普通读

-------------------------------------------------------------
上面通过一个例子稍微演示了volatile指令的内存屏障图例。





volatile的内存屏障插入策略非常保守，其实在实际中，只要不改变volatile写-读得内存语义，编译器可以根据具体情况优化，省略不必要的屏障。
-------------------------------------------------------------
public class VolatileBarrierExample {
    int a = 0;
    volatile int v1 = 1;
    volatile int v2 = 2;

    void readAndWrite(){
        int i = v1;     //volatile读
        int j = v2;     //volatile读
        a = i + j;      //普通读
        v1 = i + 1;     //volatile写
        v2 = j * 2;     //volatile写
    }
}
-------------------------------------------------------------

没有优化的示例图 如下：

int i = v1;

LoadLoad屏障   （1）

LoadStore屏障   （2）

int j = v2;

LoadLoad屏障   （3）

LoadStore屏障   （4）

a = i + j;(普通写)

StoreStore屏障   （5）

v1 = i + 1;

StoreLoad屏障   （6）

StoreStore屏障   （7）

v2 = j * 2;

StoreLoad屏障   （8）





更具规则得出  236 可以省略

























/-----------------------------------------------------------------------------------/
/-----------------------------------我是分割线--------------------------------------/
/-----------------------------------------------------------------------------------/

[Java内存模型之从JMM角度分析DCL（Double Check Lock 中卫双重检查锁定）]  

单例模式里面的懒汉式：
-------------------------------------------------------------
public class Singleton {
   private static Singleton singleton;

   private Singleton(){}

   public static Singleton getInstance(){
       if(singleton == null){
           singleton = new Singleton();
       }

       return singleton;
   }
} 
-------------------------------------------------------------

这种写法是错误的，因为它无法保证线程的安全性。优化如下：

-------------------------------------------------------------
public class Singleton {
   private static Singleton singleton;

   private Singleton(){}

   public static synchronized Singleton getInstance(){
       if(singleton == null){
           singleton = new Singleton();
       }

       return singleton;
   }
}
-------------------------------------------------------------

优化非常简单，就是在getInstance方法上面做了同步，但是synchronized就会导致这个方法比较低效，导致程序性能下降

-------------------------------------------------------------
public class Singleton {
   private static Singleton singleton;

   private Singleton(){}

   public static Singleton getInstance(){
       if(singleton == null){                              // 1
           synchronized (Singleton.class){                 // 2
               if(singleton == null){                      // 3
                   singleton = new Singleton();            // 4
               }
           }
       }
       return singleton;
   }
}
-------------------------------------------------------------

优点如下：

1.如果检查第一个singleton不为null,则不需要执行下面的加锁动作，极大提高了程序的性能；

2.如果第一个singleton为null,即使有多个线程同一时间判断，但是由于synchronized的存在，只会有一个线程能够创建对象；

3.当第一个获取锁的线程创建完成后singleton对象后，其他的在第二次判断singleton一定不会为null，则直接返回已经创建好的singleton对象；、



不过仍然错误！！


创建对象过程，实例化一个对象要分为三个步骤：

1.分配内存空间

2.初始化对象

3.将内存空间的地址赋值给对应的引用

由于 步骤2和3 可能发生重排

1.分配内存空间

2.将内存空间的地址赋值给对应的引用

3.初始化对象

如果2、3发生了重排序就会导致第二个判断会出错，singleton != null，
但是它其实仅仅只是一个地址而已，此时对象还没有被初始化，所以return的singleton对象是一个没有被初始化的对象。

所以我们可以得出DCL错误根源在于步骤4：

singleton = new Singleton();





/-----------------------------------------------------------------------------------/

[基于volatile解决方案（重要）]

-------------------------------------------------------------
public class Singleton {
   //通过volatile关键字来确保安全
   private volatile static Singleton singleton;

   private Singleton(){}

   public static Singleton getInstance(){
       if(singleton == null){
           synchronized (Singleton.class){
               if(singleton == null){
                   singleton = new Singleton();
               }
           }
       }
       return singleton;
   }
}
-------------------------------------------------------------
当singleton声明为volatile后，步骤2、步骤3就不会被重排序了，也就可以解决上面那问题了。



[基于类初始化的解决方案]

该解决方案的根本就在于：利用classloder的机制来保证初始化instance时只有一个线程。
JVM在类初始化阶段会获取一个锁，这个锁可以同步多个线程对同一个类的初始化。

-------------------------------------------------------------
public class Singleton {
   private static class SingletonHolder{
       public static Singleton singleton = new Singleton();
   }

   public static Singleton getInstance(){
       return SingletonHolder.singleton;
   }
}
-------------------------------------------------------------



Java语言规定，对于每一个类或者接口C,都有一个唯一的初始化锁LC与之相对应。从C到LC的映射，由JVM的具体实现去自由实现。
JVM在类初始化阶段期间会获取这个初始化锁，并且每一个线程至少获取一次锁来确保这个类已经被初始化过了。


线程A -------------->                                            1.分配内存空间
        试图获取锁      ---------------------    线程A执行
                        |class对象的初始化锁| ------------------> 2.设置singleton指向内存空间
                        ---------------------
                                                                 3.初始化对象
线程B -------------->
        试图获取锁























/-----------------------------------------------------------------------------------/
/-----------------------------------我是分割线--------------------------------------/
/-----------------------------------------------------------------------------------/

[Java内存模型之总结]
JMM 规定了线程的工作内存和主内存的交互关系，以及线程之间的可见性和程序的执行顺序。
一方面要为程序员提供足够强的内存可见性保证；
另一方面对编译器和处理器的限制要尽可能的放松；
JMM对程序员屏蔽了CPU以及OS内存的使用问题，能够使程序在不同的CPU和OS内存上都能够达到预期的效果。


java采用内存共享的模式来实现线程之间的通信。编译器和处理器可以对程序进行重排序优化处理，但要遵守一些规则：

1.原子性：一个操作或者多个操作要么全部执行要么全部不执行；

2.可见性：当多个线程同时访问一个共享变量时，如果其中某个线程更改了该共享变量，其他线程应该可以立刻看到这个改变；

3.有序性：程序的执行要按照代码的先后顺序执行；


JMM对原子性没有提供解决方案，但解决了可见性和有序性，原子性则需要通过锁或者Synchronized。

如果一个操作A的操作结果需要对操作B可见，那么我们就认为操作A和操作B之间存在happens-before关系，即A happens-before B

happens-before 不是顺序关系，而是[前者对于后者可见]。

happens-before原则是JMM中非常重要的一个原则，它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，
我们可以解决在并发环境下两个操作之间是否存在冲突的所有问题。
JMM规定，两个操作存在happens-before关系并不一定要A操作先于B操作执行，只要A操作的结果对B操作可见即可。

在程序运行过程中，为了执行的效率，编译器和处理器是可以对程序进行一定的重排序，但是他们必须要满足两个条件：1 执行的结果保持不变，2 存在数据依赖的不能重排序。重排序是引起多线程不安全的一个重要因素。